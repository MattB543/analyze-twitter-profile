A screenshot of an online article titled "What you can do about AI 2027," authored by Eli Lifland and published on June 28, 2025, discusses how to steer toward a positive Artificial General Intelligence (AGI) future. The article warns of a potential scenario where humanity loses control of its destiny by 2027 and faces extinction by 2030, posing the question of how to avoid this outcome. It emphasizes the need to "Act with urgency but not certainty," stating that AGI in 2027 is a plausible outcome and society may only have two years left before its fate is sealed, while advising against extreme uncooperative actions due to the uncertainty of AGI timelines, which the author's team's median range from 2028 to 2032, and suggests that AI progress may slow down in the 2030s, encouraging preparation to contribute if AGI arrives post-2027.